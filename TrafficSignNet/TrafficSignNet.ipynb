{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrafficSignNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V1nlWQQO3vh",
        "colab_type": "text"
      },
      "source": [
        "Dataset Used: German Traffic Sign Recognition Benchmark\n",
        "(GTSRB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZjVWKAIPIB9",
        "colab_type": "text"
      },
      "source": [
        "Structure: Conv2D(32) -> Activation -> BatchNorm -> MaxPool2D(16) -> FC -> FC -> Softmax\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXscfqABbVpf",
        "colab_type": "code",
        "outputId": "a923ebf5-94f9-4a4f-8021-3d94b149e8b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYTvvHfo5oaP",
        "colab_type": "text"
      },
      "source": [
        "**Kaggle Config**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SFdCGljrcN0",
        "colab_type": "code",
        "outputId": "817c3158-6c2e-41dc-c915-cc1a814f1b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.6.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M2jsvttrfkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir .kaggle  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHIpGZsKr4Ja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "token = {\"username\":\"rajatsahay\",\"key\":\"xxxxxxxxxxxxxxxx\"}\n",
        "with open('/content/drive/My Drive/.kaggle/kaggle.json', 'w') as file:\n",
        "  json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liiJVqbw2VOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaxiZ9Y24UzI",
        "colab_type": "code",
        "outputId": "53ef2cd0-2d2d-40de-a12f-56ceea47b12f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!kaggle config set -n path -v{/content}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_B0riC-tiJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 /content/drive/My\\ Drive/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsy4ufbuurbo",
        "colab_type": "code",
        "outputId": "f156461c-3835-4267-8993-4d2253c4b5ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                      title                                               size  lastUpdated          downloadCount  \n",
            "-------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  \n",
            "gustavomodelli/forest-fires-in-brazil                    Forest Fires in Brazil                              31KB  2019-08-24 16:09:16          18126  \n",
            "rajeevw/ufcdata                                          UFC-Fight historical data from 1993 to 2019          3MB  2019-07-05 09:58:02          12764  \n",
            "tristan581/17k-apple-app-store-strategy-games            17K Mobile Strategy Games                            8MB  2019-08-26 08:22:16          14189  \n",
            "chirin/africa-economic-banking-and-systemic-crisis-data  Africa Economic, Banking and Systemic Crisis Data   14KB  2019-07-21 02:00:17           6535  \n",
            "akhilv11/border-crossing-entry-data                      Border Crossing Entry Data                           4MB  2019-08-21 14:51:34           7202  \n",
            "kapilverma/hindi-bible                                   Hindi Bible                                          5MB  2019-09-07 18:04:35            543  \n",
            "ruslankl/european-union-lgbt-survey-2012                 EU LGBT Survey                                     610KB  2019-07-19 11:15:25           2522  \n",
            "shuyangli94/food-com-recipes-and-user-interactions       Food.com Recipes and Interactions                  267MB  2019-11-08 01:18:21           5037  \n",
            "pascalbliem/european-social-survey-ess-8-ed21-201617     European Social Survey (ESS) 8 ed2.1 (2016/17)      10MB  2019-09-29 07:30:37           1362  \n",
            "grikomsn/amazon-cell-phones-reviews                      Amazon Cell Phones Reviews                          10MB  2019-09-29 02:26:48           5039  \n",
            "brkurzawa/us-breweries                                   US Breweries                                        76KB  2019-10-02 03:15:27           3616  \n",
            "srikantsahu/co2-and-ghg-emission-data                    CO2 and GHG emission data                           91KB  2019-09-26 20:10:59           3231  \n",
            "jojoker/singapore-airbnb                                 Singapore Airbnb                                   350KB  2019-09-25 22:05:44           4114  \n",
            "hmavrodiev/sofia-air-quality-dataset                     Sofia air quality dataset                            3GB  2019-09-14 05:48:09           2291  \n",
            "irinachuchueva/russian-wholesale-electricity-market      Russian Wholesale Electricity Market                 1MB  2019-10-09 08:20:57           1308  \n",
            "mabusalah/brent-oil-prices                               Brent Oil Prices                                    38KB  2019-10-14 12:31:05           3120  \n",
            "smid80/canadian-federal-election-results-timeseries      Canadian Federal Election Results (Timeseries)      18MB  2019-10-09 11:08:29           1216  \n",
            "nitinsss/military-expenditure-of-countries-19602019      Military Spending of Countries (1960-2019)          55KB  2019-10-10 12:17:37           5344  \n",
            "valentynsichkar/traffic-signs-preprocessed               Traffic Signs Preprocessed                           4GB  2019-08-31 18:22:11           2244  \n",
            "hmavrodiev/london-bike-sharing-dataset                   London bike sharing dataset                        165KB  2019-10-10 12:49:37           6285  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0jsHMdku3gs",
        "colab_type": "code",
        "outputId": "6955f4a6-44c2-4a48-e6c0-4803aec7ca57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "!kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading gtsrb-german-traffic-sign.zip to {/content}/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\n",
            "100% 611M/612M [00:04<00:00, 127MB/s]\n",
            "100% 612M/612M [00:04<00:00, 141MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUoOwjnYBYeb",
        "colab_type": "code",
        "outputId": "3f48b6d7-cc44-4b1a-fd9c-bd73b4321ffd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gtsrb-german-traffic-sign.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK_Mk7qg6AR6",
        "colab_type": "text"
      },
      "source": [
        "**Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL5Wwf2wPW9P",
        "colab_type": "code",
        "outputId": "e6c5d882-a9ae-40a8-fa65-6edbf7039da2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "#MODEL\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization\n",
        "from keras.layers import Activation,Flatten,Dropout,Dense\n",
        "\n",
        "class TrafficSignNet:\n",
        "  @staticmethod\n",
        "  def build(width,height,depth,classes):\n",
        "    model=Sequential()\n",
        "    inputShape=(height,width,depth)\n",
        "    chanDim=-1\n",
        "\n",
        "    #Conv2D->Relu->BatchNorm->MaxPool\n",
        "\n",
        "    ## size=32x32 ##\n",
        "    model.add(Conv2D(8,(5,5),padding=\"same\",input_shape=inputShape))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    \n",
        "    ## size=16x16 ##\n",
        "\n",
        "    #first set (Conv->ReLU->Conv->ReLU)*2->MaxPool\n",
        "    model.add(Conv2D(16,(3,3),padding=\"same\"))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(Conv2D(16,(3,3),padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    ## size=3x3 ##\n",
        "\n",
        "    #second set (Conv->ReLU->Conv->ReLU)*2->MaxPool\n",
        "    model.add(Conv2D(32,(3,3),padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=ChanDim))\n",
        "    model.add(Conv2D(32,(3,3),padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=ChanDim))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    #Two sets of FC and softmax classifier\n",
        "    \n",
        "    #first set\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    #second set\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    #softmax\n",
        "    model.add(Dense(classes))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUOxzPPWP_Fg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "%matplotlib notebook\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "from skimage import transform,exposure,io\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "#keras patch: ImageDataGenerator is now in keras.preprocessing.image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejKBrWnYU2jq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_split(basePath,csvPath):\n",
        "  #data,labels\n",
        "  data=[]\n",
        "  labels=[]\n",
        "\n",
        "  #load contenst of .csv file, remove header (top line) and shuffle contents\n",
        "  rows=open(csvPath).read().strip().split(\"\\n\")[1:]\n",
        "  random.shuffle(rows)\n",
        "\n",
        "  #loop over rows\n",
        "  for (i,row) in enumerate(rows):\n",
        "    if i>0 and i%1000==0:\n",
        "      print(\"Processed {} images\".format(i))\n",
        "\n",
        "    #split to get class ID and img path\n",
        "    (label,imagePath)=row.strip().split(\",\")[-2:]\n",
        "    imagePath=os.path.sep.join([basePath,imagePath])\n",
        "\n",
        "    image=io.imread(imagePath)\n",
        "\n",
        "    #use CLAHE to improve contrast of images (https://imagej.net/Enhance_Local_Contrast_(CLAHE))\n",
        "    #resize img to 32x32 pixels ignoring aspect ratio and perform CLAHE\n",
        "\n",
        "    image=transform.resize(image,(32,32))\n",
        "    labels.append(int(label))\n",
        "\n",
        "  data=np.array(data)\n",
        "  labels=np.array(labels)\n",
        "\n",
        "  return (data,labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uogglz20Vqyd",
        "colab_type": "code",
        "outputId": "c4fe3683-bee8-4fb1-fda6-c6d6a58c2c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "#PreReq\n",
        "num_epochs=30\n",
        "init_lr=1e-3 #learning rate\n",
        "bs=64 #batch size\n",
        "\n",
        "labelNames=open(\"signnames.csv\").read().strip().split(\"\\n\")[1:]\n",
        "labelNames=[l.split(\",\")[1] for l in labelNames]\n",
        "\n",
        "\n",
        "#TODO\n",
        "\n",
        "path_to_model=\"/content/drive/My Drive/{/content}/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\"\n",
        "path_to_Traindataset=\"/content/drive/My Drive/{/content}/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\"\n",
        "path_to_Testdataset=\"/content/drive/My Drive/{/content}/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\"\n",
        "\n",
        "trainPath=os.path.sep.join([path_to_Traindataset,\"Train.csv\"])\n",
        "testPath=os.path.sep.join([path_to_Testdataset,\"Test.csv\"])\n",
        "\n",
        "#load training and testing data\n",
        "print(\"Loading Training and Testing Data\")\n",
        "(trainX,trainY)=load_split(path_to_Traindataset,trainPath)\n",
        "(testX,testY)=load_split(path_to_Testdataset,testPath)\n",
        "\n",
        "#scale data to range [0.1]\n",
        "trainX=trainX.astype(\"float32\")/255.0\n",
        "testX=testX.astype(\"float32\")/255.0\n",
        "\n",
        "#one-hot encode labels\n",
        "numLabels=len(np.unique(trainY))\n",
        "trainY=to_categorical(trainY,numLabels)\n",
        "testY=to_categorical(testY,numLabels)\n",
        "\n",
        "#account for skew in labelled data\n",
        "classTotals=trainY.sum(axis=0)\n",
        "classWeight=classTotals.max()/classTotals\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Training and Testing Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-18a9464d0ead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#load training and testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading Training and Testing Data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_Traindataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_Testdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-4a92a931a216>\u001b[0m in \u001b[0;36mload_split\u001b[0;34m(basePath, csvPath)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mimagePath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbasePath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimagePath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#use CLAHE to improve contrast of images (https://imagej.net/Enhance_Local_Contrast_(CLAHE))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, flatten, **plugin_args)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m                                (plugin, kind))\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Get reader and read first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[0;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;31m# Create request object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# Get format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# Parse what was given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# Set extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/content/drive/My Drive/{/content}/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign/Train/5/00005_00035_00000.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HgBl9FLZrRx",
        "colab_type": "code",
        "outputId": "4a4c69dd-7a01-42a9-a71d-df5169c79d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#Image data generator for data augmentation\n",
        "aug=ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False,\n",
        "    fill_mode=\"nearest\"   \n",
        ")\n",
        "\n",
        "#initialize optimizer and compile model\n",
        "print(\"Compiling Model\")\n",
        "opt=Adam(lr=init_lr,decay=init_lr/(num_epochs*0.5))\n",
        "model=TrafficSignNet.build(width=32,height=32,depth=3,classes=numLabels)\n",
        "\n",
        "'''model.compile(loss=\"categorical_crossentropy\",optimizer=opt,\n",
        "             metrics=[\"accuracy\"])'''\n",
        "\n",
        "#Train\n",
        "print(\"Training Network\")\n",
        "H=model.fit_generator(\n",
        "    aug.flow(trainX,trainY,batch_size=bs),\n",
        "    validation_data=(testX,testY),\n",
        "    steps_per_epoch=trainX.shape[0]//BS,\n",
        "    epochs=num_epochs,\n",
        "    class_weight=classWeight,\n",
        "    verbose=1\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-4f04d3897186>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Compiling Model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_lr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrafficSignNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumLabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m '''model.compile(loss=\"categorical_crossentropy\",optimizer=opt,\n",
            "\u001b[0;31mNameError\u001b[0m: name 'numLabels' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFna-llwb7_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluate network\n",
        "predictions=model.predict(testX,batch_size=bs)\n",
        "print(classification_report(testY.argmax(axis=1),predictions.argmax(axis=1),target_names=labelNames))\n",
        "\n",
        "model.save(path_to_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBQXCNosu4xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot training loss and accuracy\n",
        "N=np.arrange(0,num_epochs)\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(N,H.history[\"loss\"],label=\"train_loss\")\n",
        "plt.plot(N, H.history[\"val_loss\"],label=\"val_loss\")\n",
        "plt.plot(N, H.history[\"accuracy\"],label=\"train_acc\")\n",
        "plt.plot(N, H.history[\"val_accuracy\"],label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq-NKNXYvRVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preds\n",
        "from keras.models import load_model\n",
        "import cv2\n",
        "\n",
        "model=load_model(path_to_model)\n",
        "labelNames=open(\"signnames.csv\").read().strip().split(\"\\n\")[1:]\n",
        "labelNames=[l.split(\",\")[1] for l in labelNames]\n",
        "\n",
        "print(\"Predicting\")\n",
        "imagePaths=list(paths.list_images(args[\"images\"]))            ###\n",
        "random.shuffle(imagePaths)\n",
        "imagePaths=imagePaths[:25]\n",
        "for (i,imagePath) in enumerate(imagePaths):\n",
        "\timage=io.imread(imagePath)\n",
        "\timage=transform.resize(image, (32, 32))\n",
        "\timage=exposure.equalize_adapthist(image, clip_limit=0.1)\n",
        " \n",
        "\t#preprocess image by scaling it to the range [0, 1]\n",
        "\timage=image.astype(\"float32\") / 255.0\n",
        "\timage=np.expand_dims(image, axis=0)\n",
        " \n",
        "\t#make predictions using the traffic sign recognizer CNN\n",
        "\tpreds=model.predict(image)\n",
        "\tj=preds.argmax(axis=1)[0]\n",
        "\tlabel=labelNames[j]\n",
        " \n",
        "\t#load the image using OpenCV, resize it, and draw the label\n",
        "\timage=cv2.imread(imagePath)\n",
        "\timage=imutils.resize(image, width=128)\n",
        "\tcv2.putText(image, label,(5,15),cv2.FONT_HERSHEY_SIMPLEX,\n",
        "\t\t0.45,(0,0,255),2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx1VtSUgZqAn",
        "colab_type": "code",
        "outputId": "6814a497-331f-452a-dff4-658f0e558598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "open(\"signnames.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.TextIOWrapper name='signnames.csv' mode='r' encoding='UTF-8'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l1kTu8JZqgf",
        "colab_type": "code",
        "outputId": "f29550c5-2e03-4194-f297-cd708a022aff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.TextIOWrapper name='Test.csv' mode='r' encoding='UTF-8'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XdIkZweaFjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}